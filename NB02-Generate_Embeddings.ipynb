{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd1fc2d4",
   "metadata": {},
   "source": [
    "# Generating Embeddings\n",
    "\n",
    "In this notebook we will generate embeddings using both the ClimateBERT model and Word2Vec using the following structure:\n",
    "\n",
    "1. Reading the data and documents from the database\n",
    "2. Download and store the embeddings models\n",
    "3. Create a new table for storing the embeddings and some original data we want. Generate embeddings using both models and store them into the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f71e567c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import os\n",
    "import regex as re\n",
    "from tqdm.notebook import tqdm\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pgai\n",
    "import torch\n",
    "import glob\n",
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM\n",
    "\n",
    "\n",
    "tqdm.pandas() #check if i should put it here\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "#connecting to the database\n",
    "load_dotenv() #loads the .env file into os.environ\n",
    "engine = create_engine(os.getenv(\"DB_URL\"))\n",
    "\n",
    "#create session\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n",
    "\n",
    "#word2vec model imports\n",
    "import psycopg2\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.downloader import load\n",
    "from gensim.utils import simple_preprocess\n",
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "\n",
    "#importing functions\n",
    "from functions import generate_embeddings_for_text, embed_and_store_all_embeddings, train_custom_word2vec_from_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802840d",
   "metadata": {},
   "source": [
    "## 1. Read the data from the database\n",
    "\n",
    "So it's easier to access the data in case the kernel crashes and had to re-run the codes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df9578b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>document_metadata.collection_summary</th>\n",
       "      <th>document_metadata.collection_title</th>\n",
       "      <th>document_metadata.corpus_type_name</th>\n",
       "      <th>document_metadata.corpus_import_id</th>\n",
       "      <th>document_metadata.category</th>\n",
       "      <th>document_metadata.description</th>\n",
       "      <th>document_metadata.document_title</th>\n",
       "      <th>document_metadata.family_import_id</th>\n",
       "      <th>document_metadata.family_slug</th>\n",
       "      <th>...</th>\n",
       "      <th>pipeline_metadata.parser_metadata.azure_model_id</th>\n",
       "      <th>pipeline_metadata.parser_metadata.parsing_date</th>\n",
       "      <th>text_block.text_block_id</th>\n",
       "      <th>text_block.language</th>\n",
       "      <th>text_block.type</th>\n",
       "      <th>text_block.type_confidence</th>\n",
       "      <th>text_block.coords</th>\n",
       "      <th>text_block.page_number</th>\n",
       "      <th>text_block.text</th>\n",
       "      <th>text_block.index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCLW.document.i00001343.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The national vision on combatting climate c...</td>\n",
       "      <td>National Strategy on Climate Change and Action...</td>\n",
       "      <td>CCLW.family.i00001342.n0000</td>\n",
       "      <td>national-strategy-on-climate-change-and-action...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCLW.document.i00001343.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;The national vision on combatting climate c...</td>\n",
       "      <td>National Strategy on Climate Change and Action...</td>\n",
       "      <td>CCLW.family.i00001342.n0000</td>\n",
       "      <td>national-strategy-on-climate-change-and-action...</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>2731</td>\n",
       "      <td>en</td>\n",
       "      <td>TableCell</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{70.6392,596.3976},{244.548,596.3976},{244.54...</td>\n",
       "      <td>83.0</td>\n",
       "      <td>Modelling Scenario Considered Type of Instrument</td>\n",
       "      <td>2731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>1706</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{69.3576,551.1744},{473.8104,551.1744},{473.8...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>EE targets based on Article 3 of Directive 201...</td>\n",
       "      <td>1706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCLW.document.i00000002.n0000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Laws and Policies</td>\n",
       "      <td>CCLW.corpus.i00000001.n0000</td>\n",
       "      <td>Executive</td>\n",
       "      <td>&lt;p&gt;&lt;span style=\"font-size: 10pt;font-family: A...</td>\n",
       "      <td>National Energy and Climate Plan 2019 Draft</td>\n",
       "      <td>CCLW.family.i00000001.n0000</td>\n",
       "      <td>national-energy-and-climate-plan_8a4f</td>\n",
       "      <td>...</td>\n",
       "      <td>prebuilt-document</td>\n",
       "      <td>2023-12-11T11:43:23.509480</td>\n",
       "      <td>1707</td>\n",
       "      <td>en</td>\n",
       "      <td>Text</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{{69.71039999999999,570.1536},{524.5488,569.79...</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Â· Energy savings goal referring to final energ...</td>\n",
       "      <td>1707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     document_id document_metadata.collection_summary  \\\n",
       "0  CCLW.document.i00001343.n0000                                 None   \n",
       "1  CCLW.document.i00001343.n0000                                 None   \n",
       "2  CCLW.document.i00000002.n0000                                 None   \n",
       "3  CCLW.document.i00000002.n0000                                 None   \n",
       "4  CCLW.document.i00000002.n0000                                 None   \n",
       "\n",
       "  document_metadata.collection_title document_metadata.corpus_type_name  \\\n",
       "0                               None                  Laws and Policies   \n",
       "1                               None                  Laws and Policies   \n",
       "2                               None                  Laws and Policies   \n",
       "3                               None                  Laws and Policies   \n",
       "4                               None                  Laws and Policies   \n",
       "\n",
       "  document_metadata.corpus_import_id document_metadata.category  \\\n",
       "0        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "1        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "2        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "3        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "4        CCLW.corpus.i00000001.n0000                  Executive   \n",
       "\n",
       "                       document_metadata.description  \\\n",
       "0  <p>The national vision on combatting climate c...   \n",
       "1  <p>The national vision on combatting climate c...   \n",
       "2  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "3  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "4  <p><span style=\"font-size: 10pt;font-family: A...   \n",
       "\n",
       "                    document_metadata.document_title  \\\n",
       "0  National Strategy on Climate Change and Action...   \n",
       "1  National Strategy on Climate Change and Action...   \n",
       "2       National Energy and Climate Plan 2019 Draft    \n",
       "3       National Energy and Climate Plan 2019 Draft    \n",
       "4       National Energy and Climate Plan 2019 Draft    \n",
       "\n",
       "  document_metadata.family_import_id  \\\n",
       "0        CCLW.family.i00001342.n0000   \n",
       "1        CCLW.family.i00001342.n0000   \n",
       "2        CCLW.family.i00000001.n0000   \n",
       "3        CCLW.family.i00000001.n0000   \n",
       "4        CCLW.family.i00000001.n0000   \n",
       "\n",
       "                       document_metadata.family_slug  ...  \\\n",
       "0  national-strategy-on-climate-change-and-action...  ...   \n",
       "1  national-strategy-on-climate-change-and-action...  ...   \n",
       "2              national-energy-and-climate-plan_8a4f  ...   \n",
       "3              national-energy-and-climate-plan_8a4f  ...   \n",
       "4              national-energy-and-climate-plan_8a4f  ...   \n",
       "\n",
       "  pipeline_metadata.parser_metadata.azure_model_id  \\\n",
       "0                                             None   \n",
       "1                                             None   \n",
       "2                                prebuilt-document   \n",
       "3                                prebuilt-document   \n",
       "4                                prebuilt-document   \n",
       "\n",
       "  pipeline_metadata.parser_metadata.parsing_date text_block.text_block_id  \\\n",
       "0                                           None                     None   \n",
       "1                                           None                     None   \n",
       "2                     2023-12-11T11:43:23.509480                     2731   \n",
       "3                     2023-12-11T11:43:23.509480                     1706   \n",
       "4                     2023-12-11T11:43:23.509480                     1707   \n",
       "\n",
       "  text_block.language text_block.type text_block.type_confidence  \\\n",
       "0                None            None                        NaN   \n",
       "1                None            None                        NaN   \n",
       "2                  en       TableCell                        1.0   \n",
       "3                  en            Text                        1.0   \n",
       "4                  en            Text                        1.0   \n",
       "\n",
       "                                   text_block.coords text_block.page_number  \\\n",
       "0                                               None                    NaN   \n",
       "1                                               None                    NaN   \n",
       "2  {{70.6392,596.3976},{244.548,596.3976},{244.54...                   83.0   \n",
       "3  {{69.3576,551.1744},{473.8104,551.1744},{473.8...                   58.0   \n",
       "4  {{69.71039999999999,570.1536},{524.5488,569.79...                   58.0   \n",
       "\n",
       "                                     text_block.text text_block.index  \n",
       "0                                               None                0  \n",
       "1                                               None                0  \n",
       "2   Modelling Scenario Considered Type of Instrument             2731  \n",
       "3  EE targets based on Article 3 of Directive 201...             1706  \n",
       "4  Â· Energy savings goal referring to final energ...             1707  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the table\n",
    "df = pd.read_sql('SELECT * FROM climate_policy_radar WHERE \"document_metadata.geographies\" ~ \\'ALB\\';', engine)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421c3320",
   "metadata": {},
   "source": [
    "## 2. Embeddings generation\n",
    "\n",
    "### 2.1 Download and load ClimateBERT\n",
    "\n",
    "The code below will download and load the ClimateBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9df15eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL_LOCAL_DIR = os.getenv('EMBEDDING_MODEL_LOCAL_DIR')\n",
    "EMBEDDING_MODEL = os.getenv(\"EMBEDDING_MODEL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c822ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessiefung/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:898: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n",
      "/Users/jessiefung/Desktop/DS205/group-6-final-project/.venv/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py:476: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Download\n",
    "tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "model = AutoModelForMaskedLM.from_pretrained(EMBEDDING_MODEL, use_auth_token=False)\n",
    "\n",
    "# Save it to a  local_models folder\n",
    "tokenizer.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "model.save_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7653dd76",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at local_model/climatebert/distilroberta-base-climate-f and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the embedding model\n",
    "climatebert_tokenizer = AutoTokenizer.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)\n",
    "climatebert_model = AutoModel.from_pretrained(EMBEDDING_MODEL_LOCAL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6256326f",
   "metadata": {},
   "source": [
    "### 2.2 Download and load Word2Vec\n",
    "\n",
    "This Word2Vec model is untrained. We will check if training is necessary and use the trained model if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d5d2253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Loading pretrained Word2Vec model: word2vec-google-news-300\n",
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
      "âœ… Model loaded!\n",
      "[('climate_change', 0.6569506525993347), ('Climate', 0.6230838298797607), ('climates', 0.6195024847984314), ('global_warming', 0.6047458648681641), ('environment', 0.6009921431541443), ('climatic', 0.5555011630058289), ('climatic_conditions', 0.5207005143165588), ('ambassador_Brice_Lalonde', 0.5172268152236938), ('Global_warming', 0.5048916339874268), ('Climate_Change', 0.4955976903438568)]\n"
     ]
    }
   ],
   "source": [
    "# Choose a pretrained Word2Vec model\n",
    "model_name = \"word2vec-google-news-300\"\n",
    "\n",
    "# Download and load the model\n",
    "print(f\"ðŸ”„ Loading pretrained Word2Vec model: {model_name}\")\n",
    "word2vec_model = load(model_name)\n",
    "print(\"âœ… Model loaded!\")\n",
    "\n",
    "# Example: check similarity\n",
    "print(word2vec_model.most_similar(\"climate\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5182e84d",
   "metadata": {},
   "source": [
    "Now check if the Word2Vec model is able to cover climate-specific words in the climate policy radar. If they cannot be covered we would have to train the Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9741de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Top OOV words not in Word2Vec:\n",
      "of: 5249\n",
      "and: 3486\n",
      "to: 1875\n",
      "nÂº: 310\n",
      "ambiental: 251\n",
      "artigo: 245\n",
      "anp: 185\n",
      "meio: 184\n",
      "parÃ¡grafo: 157\n",
      "emissÃµes: 152\n",
      "albania: 142\n",
      "desenvolvimento: 142\n",
      "resoluÃ§Ã£o: 136\n",
      "aÃ§Ãµes: 130\n",
      "Ã¡reas: 124\n",
      "anexo: 119\n",
      "desta: 118\n",
      "informaÃ§Ãµes: 113\n",
      "Ã s: 110\n",
      "convenÃ§Ã£o: 110\n",
      "conama: 110\n",
      "quilombola: 108\n",
      "decreto: 102\n",
      "suas: 101\n",
      "reduÃ§Ã£o: 98\n",
      "proteÃ§Ã£o: 96\n",
      "trata: 96\n",
      "quilombolas: 92\n",
      "Ã³rgÃ£os: 91\n",
      "sÃ£o: 90\n",
      "Ã³rgÃ£o: 89\n",
      "devem: 88\n",
      "aviaÃ§Ã£o: 88\n",
      "seguintes: 87\n",
      "gestÃ£o: 86\n",
      "capÃ­tulo: 85\n",
      "produÃ§Ã£o: 84\n",
      "ibama: 84\n",
      "educaÃ§Ã£o: 83\n",
      "atividades: 83\n",
      "mudanÃ§a: 80\n",
      "espÃ©cies: 80\n",
      "serÃ£o: 78\n",
      "inciso: 76\n",
      "promover: 74\n",
      "disposto: 74\n",
      "execuÃ§Ã£o: 72\n",
      "direito: 72\n",
      "conferÃªncia: 71\n",
      "efeito: 70\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \"text_block.text\"\n",
    "FROM climate_policy_radar\n",
    "WHERE \"text_block.text\" IS NOT NULL\n",
    "LIMIT 10000;\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql_query(query, engine)\n",
    "\n",
    "# 3. Tokenize and gather all unique words\n",
    "all_tokens = []\n",
    "for text in df['text_block.text']:\n",
    "    tokens = simple_preprocess(text)\n",
    "    all_tokens.extend(tokens)\n",
    "\n",
    "# 4. Compare to Word2Vec vocabulary\n",
    "vocab = set(word2vec_model.key_to_index)\n",
    "oov_words = [token for token in all_tokens if token not in vocab]\n",
    "\n",
    "# 5. Count top missing words\n",
    "oov_counter = Counter(oov_words)\n",
    "most_common_oov = oov_counter.most_common(50)\n",
    "\n",
    "# 6. Display\n",
    "print(\"âŒ Top OOV words not in Word2Vec:\")\n",
    "for word, count in most_common_oov:\n",
    "    print(f\"{word}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0dccfd",
   "metadata": {},
   "source": [
    "We can see there are some terms i.e. abbreviations and locations that are absent in word2vec. We'll train the model and also make sure the embeddings are in 768 dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7987f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the function to train the model so the absent words can be added\n",
    "\n",
    "texts = df['text_block.text'].dropna().tolist()\n",
    "\n",
    "important_terms = [\n",
    "    \"albania\", \"albanian\", \"unfccc\", \"gwp\", \"ghgs\", \"necp\", \"modelling\", \"ktoe\", \n",
    "    \"tirana\", \"vlora\", \"adriatic\", \"ionian\", \"montenegro\", \"albgaz\", \"oshee\",\n",
    "    \"lulucf\", \"neeap\", \"wbif\", \"instat\", \"tpes\", \"gwh\", \"nzeb\", \"entso\", \"smes\"\n",
    "]\n",
    "\n",
    "model = train_custom_word2vec_from_texts(\n",
    "    texts=texts,\n",
    "    force_include_words=important_terms\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2c97d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 'albania' in vocab | Dim: 768\n",
      "âœ… 'unfccc' in vocab | Dim: 768\n",
      "âœ… 'gwp' in vocab | Dim: 768\n",
      "âœ… 'oshee' in vocab | Dim: 768\n",
      "âœ… 'tirana' in vocab | Dim: 768\n",
      "âœ… 'ktoe' in vocab | Dim: 768\n",
      "âœ… 'neeap' in vocab | Dim: 768\n",
      "âœ… 'smes' in vocab | Dim: 768\n"
     ]
    }
   ],
   "source": [
    "# DOUBLE CHECK IF THE MODEL IS LOADED CORRECTLY\n",
    "# Load model if needed\n",
    "\n",
    "model = Word2Vec.load(\"./local_model/custom_word2vec_768.model\")\n",
    "\n",
    "\n",
    "# List of words you want to check\n",
    "words_to_check = [\n",
    "    \"albania\", \"unfccc\", \"gwp\", \"oshee\", \"tirana\", \"ktoe\", \"neeap\", \"smes\"\n",
    "]\n",
    "\n",
    "# Check dimensionality and coverage\n",
    "for word in words_to_check:\n",
    "    if word in model.wv:\n",
    "        vec = model.wv[word]\n",
    "        print(f\"âœ… '{word}' in vocab | Dim: {len(vec)}\")\n",
    "    else:\n",
    "        print(f\"âŒ '{word}' NOT in vocabulary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479c8220",
   "metadata": {},
   "source": [
    "Check exisiting documents' country so when they are embedded and they are grouped together and uploaded to the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9864b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    document_metadata.geographies\n",
      "0                           {ALB}\n",
      "1                           {AND}\n",
      "2                           {ARE}\n",
      "3                           {ARG}\n",
      "4                           {AUS}\n",
      "..                            ...\n",
      "108                         {VNM}\n",
      "109                         {XKX}\n",
      "110                         {ZAF}\n",
      "111                         {ZMB}\n",
      "112                         {ZWE}\n",
      "\n",
      "[113 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT DISTINCT \"document_metadata.geographies\"\n",
    "FROM climate_policy_radar\n",
    "WHERE \"document_metadata.geographies\" IS NOT NULL;\n",
    "\"\"\"\n",
    "\n",
    "geos = pd.read_sql(query, engine)\n",
    "print(geos)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014f8ea8",
   "metadata": {},
   "source": [
    "## 3. Embedding all documents for all countries\n",
    "\n",
    "Generate embeddings for all documents and upload them into the database.\n",
    "\n",
    "**IMPORTANT THING TO DO BEFORE RUNNING THE CODE BELOW:**\n",
    "\n",
    "A new table is needed, this will be created through the create_table.sql file. Steps to run it:\n",
    "\n",
    "1. Go to create_table.sql and run the query to create the table\n",
    "2. Remember to select the Postgres Server at the bottom, and highlight the code and right click to run query\n",
    "\n",
    "\n",
    "This will create a new table in the database. The file also includes a *\"DROP TABLE IF EXISTS document_embeddings;\"* line if the table does not appear. Try not to use it after the data are uploaded because it will drop all exisisting data. Use with cautious. After creating the table, then run the code below to generate embeddings and store them into the database. This will take around 2 hours to finish running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9f7c58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at local_model/climatebert/distilroberta-base-climate-f and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Python(74729) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cebe093e03c4eaab13ec79e805402d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filtering by country:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083f16b8678242a69925a9073ad60067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing all countries:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa350ca73cb74c7db539871c9e60ae4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Embedding ALB:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a46bc5603f10447b87530b3fbfce858d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b39f67987574bd2b524c43f1ebc7fe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9998 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a92c3e2acf3d46d3a1108d4072294ea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8929b26aadf34bb8809871ff7c7ec629",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6038 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7a9143040a04b9bbf18130d8c2d07df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading ALB:   0%|          | 0/16036 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… All ClimateBERT and Word2Vec embeddings uploaded directly.\n"
     ]
    }
   ],
   "source": [
    "#Embedding and storing all embeddings in the database\n",
    "\n",
    "embed_and_store_all_embeddings(df, engine)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
