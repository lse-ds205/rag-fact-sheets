{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b10a67b",
   "metadata": {},
   "source": [
    "# Fix Paragraph Extraction in extract_document.py\n",
    "\n",
    "This notebook shows how to fix the paragraph number extraction issue where too many paragraph numbers are being assigned to each chunk. The current implementation incorrectly uses element index as paragraph number.\n",
    "\n",
    "## Problem\n",
    "- Current code assigns `paragraph_number = i + 1` based on element index\n",
    "- This creates incorrect paragraph numbering that doesn't reflect actual document structure\n",
    "- Need to implement proper paragraph tracking by page and globally\n",
    "\n",
    "## Solution\n",
    "Replace the current paragraph tracking with a proper schema that:\n",
    "1. Tracks paragraphs per page separately\n",
    "2. Maintains a global paragraph counter\n",
    "3. Uses element type changes to detect new paragraphs\n",
    "4. Stores both page-specific and global paragraph numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b37adde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's examine the current problematic code in extract_document.py\n",
    "current_problematic_code = \"\"\"\n",
    "# Current problematic implementation:\n",
    "metadata = {\n",
    "    'element_index': i,\n",
    "    'element_type': type(element).__name__,\n",
    "    'page_number': 1,  # Default value\n",
    "    'paragraph_number': None,  # This gets set incorrectly later\n",
    "    # ... other metadata\n",
    "}\n",
    "\n",
    "# Later in the code:\n",
    "if metadata['paragraph_number'] is None:\n",
    "    metadata['paragraph_number'] = i + 1  # PROBLEM: Uses element index!\n",
    "\"\"\"\n",
    "\n",
    "print(\"Current problematic approach:\")\n",
    "print(current_problematic_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead8447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the improved paragraph tracking implementation\n",
    "improved_implementation = \"\"\"\n",
    "def extract_text_from_pdf(pdf_path: str, strategy: str = \"fast\", **kwargs):\n",
    "    # ... existing code ...\n",
    "    \n",
    "    # Initialize paragraph tracking\n",
    "    paragraphs_by_page = {}  # Dict to track paragraph numbers by page\n",
    "    last_element_type = None\n",
    "    last_page_number = None\n",
    "    global_paragraph_count = 0  # Track paragraphs across the entire document\n",
    "    \n",
    "    processed_elements = []\n",
    "    \n",
    "    for i, element in enumerate(elements):\n",
    "        # ... existing element processing ...\n",
    "        \n",
    "        # Get page number from element metadata\n",
    "        page_number = 1  # default\n",
    "        if hasattr(element, 'metadata') and element.metadata:\n",
    "            if hasattr(element.metadata, 'page_number') and element.metadata.page_number:\n",
    "                page_number = element.metadata.page_number\n",
    "        \n",
    "        # Initialize paragraph counter for this page if needed\n",
    "        if page_number not in paragraphs_by_page:\n",
    "            paragraphs_by_page[page_number] = 0\n",
    "            \n",
    "        # Determine if this is a new paragraph\n",
    "        element_type = type(element).__name__\n",
    "        is_new_paragraph = False\n",
    "        \n",
    "        if page_number != last_page_number:  # New page = new paragraph\n",
    "            is_new_paragraph = True\n",
    "        elif element_type != last_element_type:  # Type change = new paragraph  \n",
    "            is_new_paragraph = True\n",
    "        elif (hasattr(element, 'category') and \n",
    "              element.category == \"NarrativeText\" and \n",
    "              last_element_type in [\"Title\", \"ListItem\"]):\n",
    "            is_new_paragraph = True\n",
    "            \n",
    "        if is_new_paragraph:\n",
    "            paragraphs_by_page[page_number] += 1\n",
    "            global_paragraph_count += 1\n",
    "            \n",
    "        # Create metadata with proper paragraph tracking\n",
    "        metadata = {\n",
    "            'element_index': i,\n",
    "            'element_type': element_type,\n",
    "            'page_number': page_number,\n",
    "            'paragraph_number': paragraphs_by_page[page_number],  # Page-specific paragraph\n",
    "            'global_paragraph_number': global_paragraph_count,    # Global paragraph\n",
    "            'paragraph_id': f\"p{page_number}_para{paragraphs_by_page[page_number]}\",\n",
    "            'extraction_strategy': strategy,\n",
    "            'filename': filename,\n",
    "            'country': country,\n",
    "            'document_title': f\"{country} NDC\"\n",
    "        }\n",
    "        \n",
    "        # Update tracking variables\n",
    "        last_element_type = element_type\n",
    "        last_page_number = page_number\n",
    "        \n",
    "        processed_elements.append({\n",
    "            'text': text,\n",
    "            'metadata': metadata\n",
    "        })\n",
    "    \n",
    "    return processed_elements\n",
    "\"\"\"\n",
    "\n",
    "print(\"Improved paragraph tracking implementation:\")\n",
    "print(improved_implementation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21121da9",
   "metadata": {},
   "source": [
    "## Key Changes Needed\n",
    "\n",
    "1. **Remove element index-based paragraph numbering**: Stop using `i + 1` as paragraph number\n",
    "2. **Add paragraph tracking by page**: Track paragraph numbers separately for each page\n",
    "3. **Add global paragraph tracking**: Maintain a counter across the entire document\n",
    "4. **Use element type changes to detect paragraphs**: Detect new paragraphs based on content structure\n",
    "5. **Store both page and global paragraph numbers**: Provide both for different use cases\n",
    "\n",
    "## Implementation Steps\n",
    "\n",
    "The following code shows the exact changes needed in the `extract_text_from_pdf` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create the complete fixed function\n",
    "def create_fixed_extract_function():\n",
    "    return '''\n",
    "def extract_text_from_pdf(\n",
    "    pdf_path: str, \n",
    "    strategy: str = \"fast\", \n",
    "    extract_images: bool = False,\n",
    "    infer_table_structure: bool = True,\n",
    "    languages: str = \"eng\",\n",
    "    **kwargs\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file using the unstructured library with proper paragraph tracking.\n",
    "    \"\"\"\n",
    "    # Validate and map strategy parameter\n",
    "    valid_strategies = [\"fast\", \"ocr_only\", \"auto\"]\n",
    "                \n",
    "    if strategy not in valid_strategies:\n",
    "        logger.warning(f\"Invalid strategy '{strategy}', using 'fast' instead\")\n",
    "        strategy = \"fast\"\n",
    "\n",
    "    try:\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        country = _extract_country_from_filename(pdf_path)\n",
    "        logger.info(f\"Extracting text from PDF: {pdf_path} using strategy: {strategy}\")\n",
    "        logger.info(f\"Detected country: {country}\")\n",
    "        \n",
    "        languages_list = [lang.strip() for lang in languages.split(',')] if languages else ['eng']\n",
    "        logger.debug(f\"Using languages: {languages_list}\")\n",
    "        \n",
    "        # Extract elements from the PDF\n",
    "        elements = partition_pdf(\n",
    "            filename=pdf_path, \n",
    "            strategy=strategy,\n",
    "            extract_images_in_pdf=extract_images,\n",
    "            infer_table_structure=infer_table_structure,\n",
    "            languages=languages_list,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        logger.info(f\"Extracted {len(elements)} elements from PDF\")\n",
    "        \n",
    "        # Initialize paragraph tracking\n",
    "        paragraphs_by_page = {}  # Dict to track paragraph numbers by page\n",
    "        last_element_type = None\n",
    "        last_page_number = None\n",
    "        global_paragraph_count = 0  # Track paragraphs across the entire document\n",
    "        \n",
    "        # Process and filter elements\n",
    "        processed_elements = []\n",
    "        has_corruption = False\n",
    "        \n",
    "        for i, element in enumerate(elements):\n",
    "            # Get text content\n",
    "            text = str(element).strip() if element else \"\"\n",
    "            \n",
    "            # Check for PDF corruption/encoding issues\n",
    "            if _has_character_corruption(text):\n",
    "                has_corruption = True\n",
    "                logger.debug(f\"Detected character corruption in element {i}: {text[:100]}...\")\n",
    "                continue  # Skip corrupted elements\n",
    "            \n",
    "            # Skip very short or empty text\n",
    "            if len(text) < 5:\n",
    "                continue\n",
    "            \n",
    "            # Skip common PDF artifacts\n",
    "            skip_patterns = [\n",
    "                r'^\\\\d+$',  # Just page numbers\n",
    "                r'^[ivxlcdm]+$',  # Roman numerals only\n",
    "                r'^[\\\\s\\\\-_=\\\\.]+$',  # Just punctuation/whitespace\n",
    "                r'^(page|pg)\\\\s*\\\\d+$',  # Page indicators\n",
    "            ]\n",
    "            \n",
    "            if any(re.match(pattern, text.lower()) for pattern in skip_patterns):\n",
    "                continue\n",
    "\n",
    "            # Get page number from element metadata\n",
    "            page_number = 1  # default\n",
    "            try:\n",
    "                if hasattr(element, 'metadata') and element.metadata:\n",
    "                    if hasattr(element.metadata, 'page_number') and element.metadata.page_number is not None:\n",
    "                        page_number = element.metadata.page_number\n",
    "                    elif hasattr(element.metadata, '__dict__'):\n",
    "                        meta_dict = element.metadata.__dict__\n",
    "                        if 'page_number' in meta_dict and meta_dict['page_number'] is not None:\n",
    "                            page_number = meta_dict['page_number']\n",
    "            except Exception as meta_error:\n",
    "                logger.warning(f\"Error extracting page number from element {i}: {meta_error}\")\n",
    "            \n",
    "            # Initialize paragraph counter for this page if needed\n",
    "            if page_number not in paragraphs_by_page:\n",
    "                paragraphs_by_page[page_number] = 0\n",
    "                \n",
    "            # Determine if this is a new paragraph\n",
    "            element_type = type(element).__name__\n",
    "            is_new_paragraph = False\n",
    "            \n",
    "            if page_number != last_page_number:  # New page = new paragraph\n",
    "                is_new_paragraph = True\n",
    "            elif element_type != last_element_type:  # Type change = new paragraph  \n",
    "                is_new_paragraph = True\n",
    "            elif (hasattr(element, 'category') and \n",
    "                  element.category == \"NarrativeText\" and \n",
    "                  last_element_type in [\"Title\", \"ListItem\"]):\n",
    "                is_new_paragraph = True\n",
    "                \n",
    "            if is_new_paragraph:\n",
    "                paragraphs_by_page[page_number] += 1\n",
    "                global_paragraph_count += 1\n",
    "            \n",
    "            # Create metadata with proper paragraph tracking\n",
    "            metadata = {\n",
    "                'element_index': i,\n",
    "                'element_type': element_type,\n",
    "                'page_number': page_number,\n",
    "                'paragraph_number': paragraphs_by_page[page_number],  # Page-specific paragraph\n",
    "                'global_paragraph_number': global_paragraph_count,    # Global paragraph\n",
    "                'paragraph_id': f\"p{page_number}_para{paragraphs_by_page[page_number]}\",\n",
    "                'extraction_strategy': strategy,\n",
    "                'filename': filename,\n",
    "                'country': country,\n",
    "                'document_title': f\"{country} NDC\"\n",
    "            }\n",
    "            \n",
    "            # Extract additional metadata if available\n",
    "            try:\n",
    "                if hasattr(element, 'metadata') and element.metadata:\n",
    "                    element_metadata = element.metadata\n",
    "                    \n",
    "                    # Extract coordinates if available\n",
    "                    if hasattr(element_metadata, 'coordinates'):\n",
    "                        metadata['coordinates'] = str(element_metadata.coordinates)\n",
    "                    elif hasattr(element_metadata, '__dict__'):\n",
    "                        meta_dict = element_metadata.__dict__\n",
    "                        if 'coordinates' in meta_dict:\n",
    "                            metadata['coordinates'] = str(meta_dict['coordinates'])\n",
    "                    \n",
    "                    # Extract filename if available\n",
    "                    if hasattr(element_metadata, 'filename'):\n",
    "                        metadata['source_file'] = element_metadata.filename\n",
    "                    elif hasattr(element_metadata, '__dict__'):\n",
    "                        meta_dict = element_metadata.__dict__\n",
    "                        if 'filename' in meta_dict:\n",
    "                            metadata['source_file'] = meta_dict['filename']\n",
    "                                    \n",
    "            except Exception as meta_error:\n",
    "                logger.warning(f\"Error extracting additional metadata from element {i}: {meta_error}\")\n",
    "            \n",
    "            # Update tracking variables\n",
    "            last_element_type = element_type\n",
    "            last_page_number = page_number\n",
    "            \n",
    "            processed_elements.append({\n",
    "                'text': text,\n",
    "                'metadata': metadata\n",
    "            })\n",
    "\n",
    "        # Handle corruption and fallback logic (existing code)\n",
    "        if has_corruption and len(processed_elements) < 5:\n",
    "            logger.warning(f\"Detected significant character corruption, attempting OCR extraction\")\n",
    "            return _retry_with_ocr(pdf_path, languages_list)\n",
    "        \n",
    "        logger.info(f\"Successfully processed {len(processed_elements)} non-empty elements\")\n",
    "        \n",
    "        if not processed_elements:\n",
    "            logger.warning(f\"No valid elements found with strategy {strategy}, attempting OCR fallback\")\n",
    "            return _retry_with_ocr(pdf_path, languages_list)\n",
    "\n",
    "        return processed_elements\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error extracting text from PDF {pdf_path}: {e}\")\n",
    "        logger.error(f\"Traceback: {traceback.format_exc()}\")\n",
    "        try:\n",
    "            logger.info(\"Attempting OCR as last resort for failed extraction\")\n",
    "            return _retry_with_ocr(pdf_path, ['eng'])\n",
    "        except:\n",
    "            return []\n",
    "'''\n",
    "\n",
    "print(\"Complete fixed function:\")\n",
    "print(create_fixed_extract_function())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a9bfb9",
   "metadata": {},
   "source": [
    "## Summary of Changes\n",
    "\n",
    "### Before (Problematic):\n",
    "```python\n",
    "# Incorrect paragraph numbering based on element index\n",
    "if metadata['paragraph_number'] is None:\n",
    "    metadata['paragraph_number'] = i + 1\n",
    "```\n",
    "\n",
    "### After (Fixed):\n",
    "```python\n",
    "# Proper paragraph tracking with page-specific and global counters\n",
    "paragraphs_by_page = {}\n",
    "global_paragraph_count = 0\n",
    "\n",
    "# Logic to detect new paragraphs based on content structure\n",
    "if is_new_paragraph:\n",
    "    paragraphs_by_page[page_number] += 1\n",
    "    global_paragraph_count += 1\n",
    "\n",
    "metadata = {\n",
    "    'paragraph_number': paragraphs_by_page[page_number],\n",
    "    'global_paragraph_number': global_paragraph_count,\n",
    "    'paragraph_id': f\"p{page_number}_para{paragraphs_by_page[page_number]}\",\n",
    "    # ... other metadata\n",
    "}\n",
    "```\n",
    "\n",
    "This approach provides:\n",
    "1. **Accurate paragraph numbering per page**\n",
    "2. **Global paragraph tracking across the document**\n",
    "3. **Paragraph IDs that reflect document structure**\n",
    "4. **Better chunk metadata for downstream processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e650b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also need to fix the OCR retry function with the same logic\n",
    "def create_fixed_ocr_function():\n",
    "    return '''\n",
    "def _retry_with_ocr(pdf_path: str, languages_list: list) -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Retry PDF extraction using OCR with proper paragraph tracking.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        logger.info(f\"Attempting OCR extraction for {pdf_path}\")\n",
    "        filename = os.path.basename(pdf_path)\n",
    "        country = _extract_country_from_filename(pdf_path)\n",
    "        \n",
    "        # Force OCR extraction\n",
    "        elements = partition_pdf(\n",
    "            filename=pdf_path, \n",
    "            strategy=\"ocr_only\",\n",
    "            extract_images_in_pdf=False,\n",
    "            infer_table_structure=True,\n",
    "            languages=languages_list\n",
    "        )\n",
    "        \n",
    "        # Initialize paragraph tracking for OCR\n",
    "        paragraphs_by_page = {}\n",
    "        last_element_type = None\n",
    "        last_page_number = None\n",
    "        global_paragraph_count = 0\n",
    "        \n",
    "        processed_elements = []\n",
    "        \n",
    "        for i, element in enumerate(elements):\n",
    "            text = str(element).strip() if element else \"\"\n",
    "            \n",
    "            # Still check for corruption in OCR results\n",
    "            if _has_character_corruption(text):\n",
    "                logger.debug(f\"OCR element {i} still has corruption, skipping\")\n",
    "                continue\n",
    "            \n",
    "            if len(text) < 10:\n",
    "                continue\n",
    "\n",
    "            # Get page number\n",
    "            page_number = 1\n",
    "            try:\n",
    "                if hasattr(element, 'metadata') and element.metadata:\n",
    "                    if hasattr(element.metadata, 'page_number') and element.metadata.page_number is not None:\n",
    "                        page_number = element.metadata.page_number\n",
    "                    elif hasattr(element.metadata, '__dict__'):\n",
    "                        meta_dict = element.metadata.__dict__\n",
    "                        if 'page_number' in meta_dict and meta_dict['page_number'] is not None:\n",
    "                            page_number = meta_dict['page_number']\n",
    "            except Exception:\n",
    "                pass\n",
    "            \n",
    "            # Initialize paragraph counter for this page\n",
    "            if page_number not in paragraphs_by_page:\n",
    "                paragraphs_by_page[page_number] = 0\n",
    "                \n",
    "            # Determine if this is a new paragraph\n",
    "            element_type = type(element).__name__\n",
    "            is_new_paragraph = False\n",
    "            \n",
    "            if page_number != last_page_number:\n",
    "                is_new_paragraph = True\n",
    "            elif element_type != last_element_type:\n",
    "                is_new_paragraph = True\n",
    "                \n",
    "            if is_new_paragraph:\n",
    "                paragraphs_by_page[page_number] += 1\n",
    "                global_paragraph_count += 1\n",
    "\n",
    "            # Create metadata with proper paragraph tracking\n",
    "            metadata = {\n",
    "                'element_index': i,\n",
    "                'element_type': element_type,\n",
    "                'page_number': page_number,\n",
    "                'paragraph_number': paragraphs_by_page[page_number],\n",
    "                'global_paragraph_number': global_paragraph_count,\n",
    "                'paragraph_id': f\"p{page_number}_para{paragraphs_by_page[page_number]}\",\n",
    "                'extraction_strategy': 'ocr_fallback',\n",
    "                'filename': filename,\n",
    "                'country': country,\n",
    "                'document_title': f\"{country} NDC\"\n",
    "            }\n",
    "            \n",
    "            # Update tracking variables\n",
    "            last_element_type = element_type\n",
    "            last_page_number = page_number\n",
    "            \n",
    "            processed_elements.append({\n",
    "                'text': text,\n",
    "                'metadata': metadata\n",
    "            })\n",
    "\n",
    "        logger.info(f\"OCR extraction completed with {len(processed_elements)} elements\")\n",
    "        return processed_elements\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"OCR extraction failed for {pdf_path}: {e}\")\n",
    "        return []\n",
    "'''\n",
    "\n",
    "print(\"Fixed OCR retry function:\")\n",
    "print(create_fixed_ocr_function())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
